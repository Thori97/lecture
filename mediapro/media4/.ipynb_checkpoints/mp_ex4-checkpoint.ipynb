{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第4回課題：夏目漱石の「吾輩は猫である」っぽい文を生成してみよう！\n",
    "\n",
    "**課題は結果が出力されている状態で保存して提出してください！**\n",
    "\n",
    "## 課題１：分かち書き文の生成\n",
    "\n",
    "`text/wagahaiwa_nekodearu_org.txt`には、夏目漱石の小説「吾輩は猫である」の本文が記録されています。   \n",
    "このテキストを半角スペース区切りの分かち書き文に変換して、`text/wagahaiwa_nekodearu_wakati.txt`に保存してください。  \n",
    "なお、改行は削除せずにそのまま残してしておいてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['吾輩 は 猫 で ある 。 名前 は まだ 無い 。']\n"
     ]
    }
   ],
   "source": [
    "test_data = open(\"text/wagahaiwa_nekodearu_org.txt\", \"r\")\n",
    "test_data2 = open(\"text/wagahaiwa_nekodearu_wakati.txt\", \"w\")\n",
    "\n",
    "contents = test_data.read()\n",
    "\n",
    "\n",
    "sentences = contents.split()\n",
    "\n",
    "from janome.tokenizer import Tokenizer\n",
    "wakatis = []\n",
    "t = Tokenizer() # <== これは辞書を読み込み、解析プログラムを起動状態にします。メモリを食うので、１つのプログラムで１回だけ実行して、あとは使いまわしてください。\n",
    "for sentence in sentences:\n",
    "    tokens = t.tokenize(sentence, wakati=True)\n",
    "    wakati= ''\n",
    "    for token in tokens:\n",
    "        wakati += token + ' '\n",
    "    wakati = wakati.rstrip()\n",
    "    test_data2.write(wakati)\n",
    "    wakatis.append(wakati)\n",
    "\n",
    "test_data.close()\n",
    "test_data2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "冒頭の1文を出力してください。  \n",
    "次のような文が出てきたら正解です。  \n",
    "```吾輩 は 猫 で ある 。 名前 は まだ 無い 。 ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['吾輩 は 猫 で ある 。 名前 は まだ 無い 。']\n"
     ]
    }
   ],
   "source": [
    "print(wakatis[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題２：ランダム文生成\n",
    "\n",
    "下のセルで、課題１で作成した`text/wagahaiwa_nekodearu_wakati.txt`を入力として、統計的tri-gramモデルを学習してください。  \n",
    "学習モデルの変数名は`lm`とします。   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 13866\n"
     ]
    }
   ],
   "source": [
    "from nltk.lm import Vocabulary\n",
    "from nltk.lm.models import MLE\n",
    "from nltk.util import ngrams\n",
    "\n",
    "file = 'text/wagahaiwa_nekodearu_wakati.txt'\n",
    "\n",
    "words = [('<BOP> ' + l + ' <EOP>').split() for l in open(file, 'r', encoding='utf-8').readlines()]\n",
    "\n",
    "\n",
    "# 読み込んだ小説集の語彙（異なり単語）を収集\n",
    "# Vocabularyは1次元のリストを受け取るが、wordsは2次元のリストなので、\n",
    "# wordsを内包表記で2次元から1次元に変換してからVocabularyに渡しています\n",
    "vocab = Vocabulary([item for sublist in words for item in sublist])\n",
    "\n",
    "# 語彙の一覧を表示させたいなら下4行のコメントを有効にする\n",
    "'''num = 0\n",
    "for v in sorted(vocab.counts):\n",
    "    print('{:d}\\t{:s}'.format(num,v))\n",
    "    num += 1\n",
    "'''\n",
    "print('Vocabulary size: ' + str(len(vocab))) # 語彙サイズ（単語の種類数）\n",
    "\n",
    "text_trigrams = [ngrams(word, 3) for word in words] # tri-gramを生成\n",
    "\n",
    "n = 3\n",
    "lm = MLE(order = n, vocabulary = vocab) # 最尤推定法（Maximum Likelihood Estimation)による統計的n-gram言語モデルの準備\n",
    "lm.fit(text_trigrams) # 上で生成したtri-gramを使って言語モデルを学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習したモデル`lm`を使って、以下のセルで「吾輩は」から始まる文を10文生成してください。   \n",
    "生成文は「吾輩は」から始めて、`。`あるいは`」`で終わる一文を基本としますが、より自然な文となるよう、独自の改良を加えても構いません。   \n",
    "**生成文が出力されている状態で保存して提出してください。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "吾輩は自白する。\n",
      "\n",
      "\n",
      "吾輩は自白する。また夫の思いでこの逆上を重んずるのは、あまり長くなるとまた迷亭が不思議そうに取り上げて飲もうと考える。おりから門の内にもぐり込んだ。\n",
      "\n",
      "\n",
      "吾輩は自白する。また夫の思いでこの逆上を重んずるのは、あまり長くなるとまた迷亭が不思議そうに取り上げて飲もうと考える。おりから門の内にもぐり込んだ。だからどんな娘を裸体にして見た時取り乱さないくらい小さいのも事実だよ、東風君がやるくらいなんだ、――人間は自分の飯を焚く事は汽船に石炭を焚いて、後を慕って裏口へ出たな、ねえ」「いやボールが飛んだら表からである。\n",
      "\n",
      "\n",
      "吾輩は自白する。また夫の思いでこの逆上を重んずるのは、あまり長くなるとまた迷亭が不思議そうに取り上げて飲もうと考える。おりから門の内にもぐり込んだ。だからどんな娘を裸体にして見た時取り乱さないくらい小さいのも事実だよ、東風君がやるくらいなんだ、――人間は自分の飯を焚く事は汽船に石炭を焚いて、後を慕って裏口へ出たな、ねえ」「いやボールが飛んだら表からである。あの光った。\n",
      "\n",
      "\n",
      "吾輩は自白する。また夫の思いでこの逆上を重んずるのは、あまり長くなるとまた迷亭が不思議そうに取り上げて飲もうと考える。おりから門の内にもぐり込んだ。だからどんな娘を裸体にして見た時取り乱さないくらい小さいのも事実だよ、東風君がやるくらいなんだ、――人間は自分の飯を焚く事は汽船に石炭を焚いて、後を慕って裏口へ出たな、ねえ」「いやボールが飛んだら表からである。あの光った。どうするのは事実の上へ、うんと力一杯茶碗の中から時々ぷうぷうと煙を吹くのが一段と不愉快を感ぜしめる。\n",
      "\n",
      "\n",
      "吾輩は自白する。また夫の思いでこの逆上を重んずるのは、あまり長くなるとまた迷亭が不思議そうに取り上げて飲もうと考える。おりから門の内にもぐり込んだ。だからどんな娘を裸体にして見た時取り乱さないくらい小さいのも事実だよ、東風君がやるくらいなんだ、――人間は自分の飯を焚く事は汽船に石炭を焚いて、後を慕って裏口へ出たな、ねえ」「いやボールが飛んだら表からである。あの光った。どうするのは事実の上へ、うんと力一杯茶碗の中から時々ぷうぷうと煙を吹くのが一段と不愉快を感ぜしめる。これは誰もくれたから、町内に馬鹿に記憶の善い山の上から薄黒い洞窟の中へ放り込んだ古毛布である。\n",
      "\n",
      "\n",
      "吾輩は自白する。また夫の思いでこの逆上を重んずるのは、あまり長くなるとまた迷亭が不思議そうに取り上げて飲もうと考える。おりから門の内にもぐり込んだ。だからどんな娘を裸体にして見た時取り乱さないくらい小さいのも事実だよ、東風君がやるくらいなんだ、――人間は自分の飯を焚く事は汽船に石炭を焚いて、後を慕って裏口へ出たな、ねえ」「いやボールが飛んだら表からである。あの光った。どうするのは事実の上へ、うんと力一杯茶碗の中から時々ぷうぷうと煙を吹くのが一段と不愉快を感ぜしめる。これは誰もくれたから、町内に馬鹿に記憶の善い山の上から薄黒い洞窟の中へ放り込んだ古毛布である。第一の方案は親子別居の制さ。\n",
      "\n",
      "\n",
      "吾輩は自白する。また夫の思いでこの逆上を重んずるのは、あまり長くなるとまた迷亭が不思議そうに取り上げて飲もうと考える。おりから門の内にもぐり込んだ。だからどんな娘を裸体にして見た時取り乱さないくらい小さいのも事実だよ、東風君がやるくらいなんだ、――人間は自分の飯を焚く事は汽船に石炭を焚いて、後を慕って裏口へ出たな、ねえ」「いやボールが飛んだら表からである。あの光った。どうするのは事実の上へ、うんと力一杯茶碗の中から時々ぷうぷうと煙を吹くのが一段と不愉快を感ぜしめる。これは誰もくれたから、町内に馬鹿に記憶の善い山の上から薄黒い洞窟の中へ放り込んだ古毛布である。第一の方案は親子別居の制さ。日本堤だぜ。\n",
      "\n",
      "\n",
      "吾輩は自白する。また夫の思いでこの逆上を重んずるのは、あまり長くなるとまた迷亭が不思議そうに取り上げて飲もうと考える。おりから門の内にもぐり込んだ。だからどんな娘を裸体にして見た時取り乱さないくらい小さいのも事実だよ、東風君がやるくらいなんだ、――人間は自分の飯を焚く事は汽船に石炭を焚いて、後を慕って裏口へ出たな、ねえ」「いやボールが飛んだら表からである。あの光った。どうするのは事実の上へ、うんと力一杯茶碗の中から時々ぷうぷうと煙を吹くのが一段と不愉快を感ぜしめる。これは誰もくれたから、町内に馬鹿に記憶の善い山の上から薄黒い洞窟の中へ放り込んだ古毛布である。第一の方案は親子別居の制さ。日本堤だぜ。筒袖を穿いて、今夜はなかなかさばけた人もいないので、さすが少しは禿げますさ。\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### ランダム文生成 ####\n",
    "# contextから始まる文を生成\n",
    "\n",
    "# 最初の2単語はいろいろと変えてみましょう\n",
    "\n",
    "for i in range(1, 10):\n",
    "    context = ['吾輩', 'は']\n",
    "    # contextのうち最後の2単語から次に繋がる確率0じゃない単語をランダムに選ぶ\n",
    "    while True:\n",
    "        w = lm.generate(text_seed=context)\n",
    "        context.append(w) # 選ばれた単語をcontextに連結 \n",
    "        if w == '。' or w == '」':\n",
    "            sentence = ''\n",
    "            for word in context:\n",
    "                sentence += word\n",
    "            print(sentence)\n",
    "            print('\\n')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "たとえば次のような文が生成されます（これは一例です）。\n",
    "```\n",
    "吾輩は文明の咒詛だ。\n",
    "吾輩はにゃあにゃあと甘えるごとく、雲を行くがごとく腹内に誘致する職務を帯びている。\n",
    "吾輩はちょっとむっとする。\n",
    "吾輩は無論しやせずして来た。\n",
    "吾輩はやはり地面の上を摩擦した女で、気の利かぬ主人は一人が「へえアンドレア・デル・サルトが言ったがそれぎれで手掛りがないから、おとなしく独乙皇帝陛下のように述べ立てる。\n",
    "吾輩は謹んで拝見すると云わぬばかりの顔も遠慮なく見るし、Ｔ１Ｔ2……。\n",
    "吾輩は少からざる尊敬をもって反覆読誦したのね。\n",
    "吾輩は年来美学上の利害もないんです。\n",
    "吾輩はこの近辺でやられて、近火の手でさあ。\n",
    "吾輩は波を打った。\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
